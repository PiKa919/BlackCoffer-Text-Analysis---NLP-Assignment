{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas requests beautifulsoup4 nltk chardet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Smdas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Smdas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Load positive and negative words with encoding detection\n",
    "        self.positive_words = self.load_words('MasterDictionary/positive-words.txt')\n",
    "        self.negative_words = self.load_words('MasterDictionary/negative-words.txt')\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def detect_encoding(self, filepath):\n",
    "        \"\"\"Detect the encoding of a file using chardet\"\"\"\n",
    "        with open(filepath, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "        return chardet.detect(raw_data)['encoding']\n",
    "    \n",
    "    def load_words(self, filepath):\n",
    "        \"\"\"Load words from file with automatic encoding detection and error handling\"\"\"\n",
    "        try:\n",
    "            # First try UTF-8\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                return set(file.read().splitlines())\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                # Detect encoding and try again\n",
    "                encoding = self.detect_encoding(filepath)\n",
    "                with open(filepath, 'r', encoding=encoding) as file:\n",
    "                    return set(file.read().splitlines())\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filepath}: {str(e)}\")\n",
    "                # Return empty set if file can't be read\n",
    "                return set()\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        return text.lower()\n",
    "    \n",
    "    def get_word_count(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        return len([word for word in words if word.lower() not in self.stop_words])\n",
    "    \n",
    "    def count_syllables(self, word):\n",
    "        word = word.lower()\n",
    "        count = 0\n",
    "        vowels = 'aeiouy'\n",
    "        \n",
    "        if word.endswith('es') or word.endswith('ed'):\n",
    "            word = word[:-2]\n",
    "        \n",
    "        prev_char_is_vowel = False\n",
    "        for char in word:\n",
    "            is_vowel = char in vowels\n",
    "            if is_vowel and not prev_char_is_vowel:\n",
    "                count += 1\n",
    "            prev_char_is_vowel = is_vowel\n",
    "            \n",
    "        if word.endswith('e'):\n",
    "            count -= 1\n",
    "        if count == 0:\n",
    "            count = 1\n",
    "        return count\n",
    "    \n",
    "    def is_complex_word(self, word):\n",
    "        return self.count_syllables(word) > 2\n",
    "    \n",
    "    def count_personal_pronouns(self, text):\n",
    "        pronouns = r'\\b(I|we|my|ours|us)\\b'\n",
    "        # Exclude 'US' when it refers to United States\n",
    "        text = re.sub(r'\\bUS\\b', '', text)\n",
    "        return len(re.findall(pronouns, text, re.IGNORECASE))\n",
    "    \n",
    "    def analyze_text(self, text):\n",
    "        try:\n",
    "            cleaned_text = self.clean_text(text)\n",
    "            \n",
    "            sentences = sent_tokenize(text)\n",
    "            words = word_tokenize(cleaned_text)\n",
    "            \n",
    "            if not words or not sentences:\n",
    "                return self.get_default_metrics()\n",
    "            \n",
    "            # Calculate scores\n",
    "            positive_score = sum(1 for word in words if word in self.positive_words)\n",
    "            negative_score = sum(1 for word in words if word in self.negative_words)\n",
    "            \n",
    "            denominator = (positive_score + negative_score) + 0.000001\n",
    "            polarity_score = (positive_score - negative_score) / denominator\n",
    "            \n",
    "            # Word count (excluding stop words)\n",
    "            word_count = self.get_word_count(cleaned_text)\n",
    "            if word_count == 0:\n",
    "                return self.get_default_metrics()\n",
    "            \n",
    "            subjectivity_score = (positive_score + negative_score) / (word_count + 0.000001)\n",
    "            \n",
    "            avg_sentence_length = word_count / len(sentences)\n",
    "            \n",
    "            complex_words = [word for word in words if self.is_complex_word(word)]\n",
    "            complex_word_count = len(complex_words)\n",
    "            \n",
    "            percent_complex_words = complex_word_count / word_count\n",
    "            \n",
    "            fog_index = 0.4 * (avg_sentence_length + percent_complex_words)\n",
    "            \n",
    "            syllable_count = sum(self.count_syllables(word) for word in words)\n",
    "            syllable_per_word = syllable_count / word_count\n",
    "            \n",
    "            personal_pronouns = self.count_personal_pronouns(text)\n",
    "            \n",
    "            avg_word_length = sum(len(word) for word in words) / word_count\n",
    "            \n",
    "            return {\n",
    "                'POSITIVE SCORE': positive_score,\n",
    "                'NEGATIVE SCORE': negative_score,\n",
    "                'POLARITY SCORE': polarity_score,\n",
    "                'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "                'AVG SENTENCE LENGTH': avg_sentence_length,\n",
    "                'PERCENTAGE OF COMPLEX WORDS': percent_complex_words,\n",
    "                'FOG INDEX': fog_index,\n",
    "                'AVG NUMBER OF WORDS PER SENTENCE': avg_sentence_length,\n",
    "                'COMPLEX WORD COUNT': complex_word_count,\n",
    "                'WORD COUNT': word_count,\n",
    "                'SYLLABLE PER WORD': syllable_per_word,\n",
    "                'PERSONAL PRONOUNS': personal_pronouns,\n",
    "                'AVG WORD LENGTH': avg_word_length\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing text: {str(e)}\")\n",
    "            return self.get_default_metrics()\n",
    "    \n",
    "    def get_default_metrics(self):\n",
    "        \"\"\"Return default metrics for error cases\"\"\"\n",
    "        return {\n",
    "            'POSITIVE SCORE': 0,\n",
    "            'NEGATIVE SCORE': 0,\n",
    "            'POLARITY SCORE': 0,\n",
    "            'SUBJECTIVITY SCORE': 0,\n",
    "            'AVG SENTENCE LENGTH': 0,\n",
    "            'PERCENTAGE OF COMPLEX WORDS': 0,\n",
    "            'FOG INDEX': 0,\n",
    "            'AVG NUMBER OF WORDS PER SENTENCE': 0,\n",
    "            'COMPLEX WORD COUNT': 0,\n",
    "            'WORD COUNT': 0,\n",
    "            'SYLLABLE PER WORD': 0,\n",
    "            'PERSONAL PRONOUNS': 0,\n",
    "            'AVG WORD LENGTH': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_article(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        title = soup.find('h1').text.strip() if soup.find('h1') else ''\n",
    "        \n",
    "        article_containers = [\n",
    "            soup.find('article'),\n",
    "            soup.find('div', class_='post-content'),\n",
    "            soup.find('div', class_='article-content'),\n",
    "            soup.find('div', class_='entry-content')\n",
    "        ]\n",
    "        \n",
    "        article = next((container for container in article_containers if container is not None), None)\n",
    "        \n",
    "        if article:\n",
    "            # Remove unwanted elements\n",
    "            for element in article.find_all(['script', 'style', 'nav', 'header', 'footer']):\n",
    "                element.decompose()\n",
    "            \n",
    "            paragraphs = article.find_all('p')\n",
    "            text = ' '.join([p.text.strip() for p in paragraphs])\n",
    "        else:\n",
    "            text = ''\n",
    "        \n",
    "        return f\"{title}\\n\\n{text}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {str(e)}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Netclan20241017: https://insights.blackcoffer.com/ai-and-ml-based-youtube-analytics-and-content-creation-tool-for-optimizing-subscriber-engagement-and-content-strategy/\n",
      "Processing Netclan20241018: https://insights.blackcoffer.com/enhancing-front-end-features-and-functionality-for-improved-user-experience-and-dashboard-accuracy-in-partner-hospital-application/\n",
      "Processing Netclan20241019: https://insights.blackcoffer.com/roas-dashboard-for-campaign-wise-google-ads-budget-tracking-using-google-ads-ap/\n",
      "Processing Netclan20241020: https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/\n",
      "Processing Netclan20241021: https://insights.blackcoffer.com/development-of-ea-robot-for-automated-trading/\n",
      "Processing Netclan20241022: https://insights.blackcoffer.com/ai-and-ml-based-youtube-analytics-and-content-creation-tool-for-optimizing-subscriber-engagement-and-content-strategy/\n",
      "Processing Netclan20241023: https://insights.blackcoffer.com/enhancing-front-end-features-and-functionality-for-improved-user-experience-and-dashboard-accuracy-in-partner-hospital-application/\n",
      "Processing Netclan20241024: https://insights.blackcoffer.com/roas-dashboard-for-campaign-wise-google-ads-budget-tracking-using-google-ads-ap/\n",
      "Processing Netclan20241025: https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/\n",
      "Processing Netclan20241026: https://insights.blackcoffer.com/transforming-and-managing-a-large-scale-sql-pedigree-database-to-neo4j-graph-db/\n",
      "Processing Netclan20241027: https://insights.blackcoffer.com/enhancing-model-accuracy-from-58-to-over-90-strategies-for-improving-predictive-performance/\n",
      "Processing Netclan20241028: https://insights.blackcoffer.com/securing-sensitive-financial-data-with-privacy-preserving-machine-learning-for-predictive-analytics/\n",
      "Processing Netclan20241029: https://insights.blackcoffer.com/enhancing-data-collection-for-research-institutions-addressing-survey-fatigue-and-incorporating-verbal-communication-for-richer-insights/\n",
      "Processing Netclan20241030: https://insights.blackcoffer.com/analyzing-the-impact-of-positive-emotions-and-pandemic-severity-on-mental-health-and-resilience-among-entrepreneurs-insights-and-predictive-modeling/\n",
      "Processing Netclan20241031: https://insights.blackcoffer.com/dynamic-brand-centric-dashboard-for-automotive-dealerships-pdf-to-financial-insights-with-flask-react-architecture-and-aws-cloud-hosting/\n",
      "Processing Netclan20241032: https://insights.blackcoffer.com/cloud-based-data-modeling-and-analysis-platform-with-drag-and-drop-interface-and-openai-api-integration-for-simulation-insights/\n",
      "Processing Netclan20241033: https://insights.blackcoffer.com/voter-profile-analysis-and-search-application-for-targeted-campaign-engagement-using-government-voter-data/\n",
      "Processing Netclan20241034: https://insights.blackcoffer.com/bert-based-classification-of-individuals-and-organizations-into-two-categories-using-natural-language-processing/\n",
      "Processing Netclan20241035: https://insights.blackcoffer.com/comprehensive-analysis-of-solana-and-ethereum-contributors-using-github-api-with-comparative-study-of-1000-random-github-profiles/\n",
      "Processing Netclan20241036: https://insights.blackcoffer.com/powerbi-rest-api-fetching-dataflow-and-refresh-schedules-with-semantic-models/\n",
      "Processing Netclan20241037: https://insights.blackcoffer.com/automated-job-data-import-and-management-solution-for-enhanced-efficiency/\n",
      "Processing Netclan20241038: https://insights.blackcoffer.com/data-analytics-and-optimization-solution-for-enhancing-renewable-energy-efficiency/\n",
      "Processing Netclan20241039: https://insights.blackcoffer.com/time-series-analysis-and-trend-forecasting-solution-for-predicting-news-trends/\n",
      "Processing Netclan20241040: https://insights.blackcoffer.com/advanced-data-visualization-solutions-for-monitoring-key-business-metrics-with-integrated-interactive-dashboards/\n",
      "Processing Netclan20241041: https://insights.blackcoffer.com/advanced-patient-data-analysis-solution-for-trend-identification-and-improved-healthcare-outcome/\n",
      "Processing Netclan20241042: https://insights.blackcoffer.com/anomaly-detection-and-analysis-for-enhanced-data-integrity-and-user-experience-on-bright-datas-website/\n",
      "Processing Netclan20241043: https://insights.blackcoffer.com/building-custom-tflite-models-and-benchmarking-on-voxl2-chips/\n",
      "Processing Netclan20241044: https://insights.blackcoffer.com/sports-prediction-model-for-multiple-sports-leagues/\n",
      "Processing Netclan20241045: https://insights.blackcoffer.com/efficient-coach-allocation-system-for-sports-coaching-organization/\n",
      "Processing Netclan20241046: https://insights.blackcoffer.com/data-studio-dashboard-with-a-data-pipeline-tool-synced-with-podio-using-custom-webhooks-and-google-cloud-function-2/\n",
      "Processing Netclan20241047: https://insights.blackcoffer.com/ai-driven-backend-for-audio-to-text-conversion-and-analytical-assessment-in-pharmaceutical-practice/\n",
      "Processing Netclan20241048: https://insights.blackcoffer.com/cloud-based-web-application-for-financial-data-processing-and-visualization-of-sp-500-metrics/\n",
      "Processing Netclan20241049: https://insights.blackcoffer.com/department-wise-kpi-tracking-dashboard-with-technician-performance-analysis-for-atoz-dependable-service/\n",
      "Processing Netclan20241050: https://insights.blackcoffer.com/steps-to-convert-a-node-js-api-to-python-for-aws-lambda-deployment/\n",
      "Processing Netclan20241051: https://insights.blackcoffer.com/building-an-analytics-dashboard-with-a-pdf-parsing-pipeline-for-data-extraction/\n",
      "Processing Netclan20241052: https://insights.blackcoffer.com/building-a-real-time-log-file-visualization-dashboard-in-kibana/\n",
      "Processing Netclan20241053: https://insights.blackcoffer.com/analyzing-the-impact-of-female-ceo-appointments-on-company-stock-prices/\n",
      "Processing Netclan20241054: https://insights.blackcoffer.com/ai-chatbot-using-llm-langchain-llama/\n",
      "Processing Netclan20241055: https://insights.blackcoffer.com/healthcare-ai-chatbot-using-llama-llm-langchain/\n",
      "Processing Netclan20241056: https://insights.blackcoffer.com/ai-bot-audio-to-audio/\n",
      "Processing Netclan20241057: https://insights.blackcoffer.com/recommendation-engine-for-insurance-sector-to-expand-business-in-the-rural-area/\n",
      "Processing Netclan20241058: https://insights.blackcoffer.com/data-from-crm-via-zapier-to-google-sheets-dynamic-to-powerbi/\n",
      "Processing Netclan20241059: https://insights.blackcoffer.com/data-warehouse-to-google-data-studio-looker-dashboard/\n",
      "Processing Netclan20241060: https://insights.blackcoffer.com/crm-monday-com-via-zapier-to-power-bi-dashboard/\n",
      "Processing Netclan20241061: https://insights.blackcoffer.com/monday-com-to-kpi-dashboard-to-manage-view-and-generate-insights-from-the-crm-data/\n",
      "Processing Netclan20241062: https://insights.blackcoffer.com/data-management-for-a-political-saas-application/\n",
      "Processing Netclan20241063: https://insights.blackcoffer.com/google-lsa-ads-google-local-service-ads-etl-tools-and-dashboards/\n",
      "Processing Netclan20241064: https://insights.blackcoffer.com/ad-networks-marketing-campaign-data-dashboard-in-looker-google-data-studio/\n",
      "Processing Netclan20241065: https://insights.blackcoffer.com/analytical-solution-for-a-tech-firm/\n",
      "Processing Netclan20241066: https://insights.blackcoffer.com/ai-solution-for-a-technology-information-and-internet-firm/\n",
      "Processing Netclan20241067: https://insights.blackcoffer.com/ai-and-nlp-based-solutions-to-automate-data-discovery-for-venture-capital-and-private-equity-principals/\n",
      "Processing Netclan20241068: https://insights.blackcoffer.com/an-etl-solution-for-an-internet-publishing-firm/\n",
      "Processing Netclan20241069: https://insights.blackcoffer.com/ai-based-algorithmic-trading-bot-for-forex/\n",
      "Processing Netclan20241070: https://insights.blackcoffer.com/equity-waterfalls-model-based-saas-application-for-real-estate-sector/\n",
      "Processing Netclan20241071: https://insights.blackcoffer.com/ai-solutions-for-foreign-exchange-an-automated-algo-trading-tool/\n",
      "Processing Netclan20241072: https://insights.blackcoffer.com/ai-agent-development-and-deployment-in-jina-ai/\n",
      "Processing Netclan20241073: https://insights.blackcoffer.com/golden-record-a-knowledge-graph-database-approach-to-unfold-discovery-using-neo4j/\n",
      "Processing Netclan20241074: https://insights.blackcoffer.com/advanced-ai-for-trading-automation/\n",
      "Processing Netclan20241075: https://insights.blackcoffer.com/create-a-knowledge-graph-to-provide-real-time-analytics-recommendations-and-a-single-source-of-truth/\n",
      "Processing Netclan20241076: https://insights.blackcoffer.com/advanced-ai-for-thermal-person-detection/\n",
      "Processing Netclan20241077: https://insights.blackcoffer.com/advanced-ai-for-road-cam-threat-detection/\n",
      "Processing Netclan20241078: https://insights.blackcoffer.com/advanced-ai-for-pedestrian-crossing-safety/\n",
      "Processing Netclan20241079: https://insights.blackcoffer.com/handgun-detection-using-yolo/\n",
      "Processing Netclan20241080: https://insights.blackcoffer.com/using-graph-technology-to-create-single-customer-view/\n",
      "Processing Netclan20241081: https://insights.blackcoffer.com/car-detection-in-satellite-images/\n",
      "Processing Netclan20241082: https://insights.blackcoffer.com/building-a-physics-informed-neural-network-for-circuit-evaluation/\n",
      "Processing Netclan20241083: https://insights.blackcoffer.com/connecting-mongodb-database-to-power-bi-dashboard-dashboard-automation/\n",
      "Processing Netclan20241084: https://insights.blackcoffer.com/data-transformation/\n",
      "Processing Netclan20241085: https://insights.blackcoffer.com/e-commerce-store-analysis-purchase-behavior-ad-spend-conversion-traffic-etc/\n",
      "Processing Netclan20241086: https://insights.blackcoffer.com/kpi-dashboard-for-accountants/\n",
      "Processing Netclan20241087: https://insights.blackcoffer.com/return-on-advertising-spend-dashboard-marketing-automation-and-analytics-using-etl-and-dashboard/\n",
      "Processing Netclan20241088: https://insights.blackcoffer.com/ranking-customer-behaviours-for-business-strategy/\n",
      "Processing Netclan20241089: https://insights.blackcoffer.com/algorithmic-trading-for-multiple-commodities-markets-like-forex-metals-energy-etc/\n",
      "Processing Netclan20241090: https://insights.blackcoffer.com/trading-bot-for-forex/\n",
      "Processing Netclan20241091: https://insights.blackcoffer.com/python-model-for-the-analysis-of-sector-specific-stock-etfs-for-investment-purposes%ef%bf%bc/\n",
      "Processing Netclan20241092: https://insights.blackcoffer.com/medical-classification/\n",
      "Processing Netclan20241093: https://insights.blackcoffer.com/design-develop-bert-question-answering-model-explanations-with-visualization/\n",
      "Processing Netclan20241094: https://insights.blackcoffer.com/design-and-develop-solution-to-anomaly-detection-classification-problems/\n",
      "Processing Netclan20241095: https://insights.blackcoffer.com/an-etl-solution-for-currency-data-to-google-big-query/\n",
      "Processing Netclan20241096: https://insights.blackcoffer.com/etl-and-mlops-infrastructure-for-blockchain-analytics/\n",
      "Processing Netclan20241097: https://insights.blackcoffer.com/an-agent-based-model-of-a-virtual-power-plant-vpp/\n",
      "Processing Netclan20241098: https://insights.blackcoffer.com/transform-api-into-sdk-library-and-widget/\n",
      "Processing Netclan20241099: https://insights.blackcoffer.com/integration-of-a-product-to-a-cloud-based-crm-platform/\n",
      "Processing Netclan20241100: https://insights.blackcoffer.com/a-web-based-dashboard-for-the-filtered-data-retrieval-of-land-records/\n",
      "Processing Netclan20241101: https://insights.blackcoffer.com/integration-of-video-conferencing-data-to-the-existing-web-app/\n",
      "Processing Netclan20241102: https://insights.blackcoffer.com/design-develop-an-app-in-retool-which-shows-the-progress-of-the-added-video/\n",
      "Processing Netclan20241103: https://insights.blackcoffer.com/auvik-connectwise-integration-in-grafana/\n",
      "Processing Netclan20241104: https://insights.blackcoffer.com/data-integration-and-big-data-performance-using-elk-stack/\n",
      "Processing Netclan20241105: https://insights.blackcoffer.com/web-data-connector/\n",
      "Processing Netclan20241106: https://insights.blackcoffer.com/an-app-for-updating-the-email-id-of-the-user-and-stripe-refund-tool-using-retool/\n",
      "Processing Netclan20241107: https://insights.blackcoffer.com/an-ai-ml-based-web-application-that-detects-the-correctness-of-text-in-a-given-video/\n",
      "Processing Netclan20241108: https://insights.blackcoffer.com/website-tracking-and-insights-using-google-analytics-google-tag-manager/\n",
      "Processing Netclan20241109: https://insights.blackcoffer.com/dashboard-to-track-the-analytics-of-the-website-using-google-analytics-and-google-tag-manager/\n",
      "Processing Netclan20241110: https://insights.blackcoffer.com/power-bi-dashboard-on-operations-transactions-and-marketing-embedding-the-dashboard-to-web-app/\n",
      "Processing Netclan20241111: https://insights.blackcoffer.com/nft-data-automation-looksrare-and-etl-tool/\n",
      "Processing Netclan20241112: https://insights.blackcoffer.com/optimize-the-data-scraper-program-to-easily-accommodate-large-files-and-solve-oom-errors/\n",
      "Processing Netclan20241113: https://insights.blackcoffer.com/making-a-robust-way-to-sync-data-from-airtables-to-mongodb-using-python-etl-solution/\n",
      "Processing Netclan20241114: https://insights.blackcoffer.com/incident-duration-prediction-infrastructure-and-real-estate/\n",
      "Processing Netclan20241115: https://insights.blackcoffer.com/statistical-data-analysis-of-reinforced-concrete/\n",
      "Processing Netclan20241116: https://insights.blackcoffer.com/database-normalization-segmentation-with-google-data-studio-dashboard-insights/\n",
      "Processing Netclan20241117: https://insights.blackcoffer.com/power-bi-dashboard-to-drive-insights-from-complex-data-to-generate-business-insights/\n",
      "Processing Netclan20241118: https://insights.blackcoffer.com/real-time-dashboard-to-monitor-infrastructure-activity-and-machines/\n",
      "Processing Netclan20241119: https://insights.blackcoffer.com/electric-vehicles-ev-load-management-system-to-forecast-energy-demand/\n",
      "Processing Netclan20241120: https://insights.blackcoffer.com/power-bi-data-driven-map-dashboard/\n",
      "Processing Netclan20241121: https://insights.blackcoffer.com/google-local-service-ads-lsa-leads-dashboard/\n",
      "Processing Netclan20241122: https://insights.blackcoffer.com/aws-lex-voice-and-chatbot/\n",
      "Processing Netclan20241123: https://insights.blackcoffer.com/metabridges-api-decentraland-integration/\n",
      "Processing Netclan20241124: https://insights.blackcoffer.com/microsoft-azure-chatbot-with-luis-language-understanding/\n",
      "Processing Netclan20241125: https://insights.blackcoffer.com/impact-of-news-media-and-press-on-innovation-startups-and-investments/\n",
      "Processing Netclan20241126: https://insights.blackcoffer.com/aws-quicksight-reporting-dashboard/\n",
      "Processing Netclan20241127: https://insights.blackcoffer.com/google-data-studio-dashboard-for-marketing-ads-and-traction-data/\n",
      "Processing Netclan20241128: https://insights.blackcoffer.com/gangala-in-e-commerce-big-data-etl-elt-solution-and-data-warehouse/\n",
      "Processing Netclan20241129: https://insights.blackcoffer.com/big-data-solution-to-an-online-multivendor-marketplace-ecommerce-business/\n",
      "Processing Netclan20241130: https://insights.blackcoffer.com/creating-a-custom-report-and-dashboard-using-the-data-got-from-atera-api/\n",
      "Processing Netclan20241131: https://insights.blackcoffer.com/azure-data-lake-and-power-bi-dashboard/\n",
      "Processing Netclan20241132: https://insights.blackcoffer.com/google-data-studio-pipeline-with-gcp-mysql/\n",
      "Processing Netclan20241133: https://insights.blackcoffer.com/quickbooks-dashboard-to-find-patterns-in-finance-sales-and-forecasts/\n",
      "Processing Netclan20241134: https://insights.blackcoffer.com/marketing-sales-and-financial-data-business-dashboard-wink-report/\n",
      "Processing Netclan20241135: https://insights.blackcoffer.com/react-native-apps-in-the-development-portfolio/\n",
      "Processing Netclan20241136: https://insights.blackcoffer.com/a-leading-firm-website-seo-optimization/\n",
      "Processing Netclan20241137: https://insights.blackcoffer.com/a-leading-hospitality-firm-in-the-usa-website-seo-optimization/\n",
      "Processing Netclan20241138: https://insights.blackcoffer.com/a-leading-firm-in-the-usa-website-seo-optimization/\n",
      "Processing Netclan20241139: https://insights.blackcoffer.com/a-leading-musical-instrumental-website-seo-optimization/\n",
      "Processing Netclan20241140: https://insights.blackcoffer.com/a-leading-firm-in-the-usa-seo-and-website-optimization/\n",
      "Processing Netclan20241141: https://insights.blackcoffer.com/immigration-datawarehouse-ai-based-recommendations/\n",
      "Processing Netclan20241142: https://insights.blackcoffer.com/lipsync-automation-for-celebrities-and-influencers/\n",
      "Processing Netclan20241143: https://insights.blackcoffer.com/key-audit-matters-predictive-modeling/\n",
      "Processing Netclan20241144: https://insights.blackcoffer.com/splitting-of-songs-into-its-vocals-and-instrumental/\n",
      "Processing Netclan20241145: https://insights.blackcoffer.com/ai-and-ml-technologies-to-evaluate-learning-assessments/\n",
      "Processing Netclan20241146: https://insights.blackcoffer.com/datawarehouse-and-recommendations-engine-for-airbnb/\n",
      "Processing Netclan20241147: https://insights.blackcoffer.com/real-estate-data-warehouse/\n",
      "Processing Netclan20241148: https://insights.blackcoffer.com/traction-dashboards-of-marketing-campaigns-and-posts/\n",
      "Processing Netclan20241149: https://insights.blackcoffer.com/google-local-service-ads-lsa-data-warehouse/\n",
      "Processing Netclan20241150: https://insights.blackcoffer.com/google-local-service-ads-missed-calls-and-messages-automation-tool/\n",
      "Processing Netclan20241151: https://insights.blackcoffer.com/marketing-ads-leads-call-status-data-tool-to-bigquery/\n",
      "Processing Netclan20241152: https://insights.blackcoffer.com/marketing-analytics-to-automate-leads-call-status-and-reporting/\n",
      "Processing Netclan20241153: https://insights.blackcoffer.com/callrail-analytics-leads-report-alert/\n",
      "Processing Netclan20241154: https://insights.blackcoffer.com/marketing-automation-tool-to-notify-lead-details-to-clients-over-email-and-phone/\n",
      "Processing Netclan20241155: https://insights.blackcoffer.com/data-etl-local-service-ads-leads-to-bigquery/\n",
      "Processing Netclan20241156: https://insights.blackcoffer.com/marbles-stimulation-using-python/\n",
      "Processing Netclan20241157: https://insights.blackcoffer.com/stocktwits-data-structurization/\n",
      "Processing Netclan20241158: https://insights.blackcoffer.com/sentimental-analysis-on-shareholder-letter-of-companies/\n",
      "Processing Netclan20241159: https://insights.blackcoffer.com/population-and-community-survey-of-america/\n",
      "Processing Netclan20241160: https://insights.blackcoffer.com/google-lsa-api-data-automation-and-dashboarding/\n",
      "Processing Netclan20241161: https://insights.blackcoffer.com/healthcare-data-analysis/\n",
      "Processing Netclan20241162: https://insights.blackcoffer.com/budget-sales-kpi-dashboard-using-power-bi/\n",
      "Processing Netclan20241163: https://insights.blackcoffer.com/amazon-buy-bot-an-automation-ai-tool-to-auto-checkouts/\n",
      "Analysis completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        input_df = pd.read_excel('Input.xlsx')\n",
    "        \n",
    "        analyzer = TextAnalyzer()\n",
    "        \n",
    "        if not os.path.exists('extracted_articles'):\n",
    "            os.makedirs('extracted_articles')\n",
    "        \n",
    "        results = []\n",
    "        for _, row in input_df.iterrows():\n",
    "            try:\n",
    "                url_id = row['URL_ID']\n",
    "                url = row['URL']\n",
    "                print(f\"Processing {url_id}: {url}\")\n",
    "                \n",
    "                article_text = scrape_article(url)\n",
    "                \n",
    "                if article_text:\n",
    "                    with open(f'extracted_articles/{url_id}.txt', 'w', encoding='utf-8') as f:\n",
    "                        f.write(article_text)\n",
    "                \n",
    "                # Analyze text\n",
    "                analysis = analyzer.analyze_text(article_text)\n",
    "                analysis['URL_ID'] = url_id\n",
    "                analysis['URL'] = url\n",
    "                results.append(analysis)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {url_id}: {str(e)}\")\n",
    "                # Add empty results for failed URLs\n",
    "                default_metrics = analyzer.get_default_metrics()\n",
    "                default_metrics['URL_ID'] = url_id\n",
    "                default_metrics['URL'] = url\n",
    "                results.append(default_metrics)\n",
    "        \n",
    "        output_df = pd.DataFrame(results)\n",
    "        \n",
    "        columns = ['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', \n",
    "                  'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS',\n",
    "                  'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT',\n",
    "                  'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']\n",
    "        output_df = output_df[columns]\n",
    "        \n",
    "        output_df.to_excel('Output Data Structure.xlsx', index=False)\n",
    "        print(\"Analysis completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
